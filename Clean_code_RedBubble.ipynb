{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "163c3d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6108b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.redbubble.com/shop/*?gender=gender-men&iaCode=u-tees&page=3&sortOrder=relevant&tShirtColor=tShirtColor-black\"\n",
    "#url=url1+page\n",
    "r = requests.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d8a310c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page number:1\n",
      "Writing:  مضمون من قبل باي بل\n"
     ]
    }
   ],
   "source": [
    "for pageN in range(100):#we want 100\n",
    "    i=pageN+1\n",
    "    page=str(i)\n",
    "    countPage=\"page number:\"+page\n",
    "    url=\"https://www.redbubble.com/shop/*?iaCode=u-tees&page=\"+pageN+\"&tShirtColor=tShirtColor-black\"\n",
    "    #+page\n",
    "    r = requests.get(url)#get the website\n",
    "    print(countPage)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')#save website contenet in soup\n",
    "    images = soup.find_all('img') #get all items called img\n",
    "    for image in images:#filter the code to get the exactly images\n",
    "        try:\n",
    "            name = image['alt'] \n",
    "            link = image['src'] \n",
    "            with open(name.replace(' ', '-').replace('/', '') + '.jpg', 'wb') as f: \n",
    "                im = requests.get(link) \n",
    "                f.write(im.content) \n",
    "                print('Writing: ', name)\n",
    "        except:\n",
    "               pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ae87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "url=\"https://www.redbubble.com/shop/*?gender=gender-men&iaCode=u-tees&page=3&sortOrder=relevant&tShirtColor=tShirtColor-black\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, 'html.parser') \n",
    "images = soup.find_all('img') \n",
    "for image in images:\n",
    "    try:\n",
    "        name = image['alt'] \n",
    "        link = image['src'] \n",
    "        with open(name.replace(' ', '-').replace('/', '') + '.jpg', 'wb') as f: \n",
    "            im = requests.get(link) \n",
    "            #lx=im.content\n",
    "            f.write(im.content) \n",
    "            img = Image.open(name).convert('L')\n",
    "            resized_img = img.resize((28, 28))\n",
    "            data_3d = np.asarray(resized_img, dtype=\"int32\")\n",
    "            new_series =pd.Series(data, index = df.columns)\n",
    "            data = data_3d.reshape(-1)\n",
    "            df = df.append(new_series, ignore_index=True)\n",
    "            \n",
    "            print('Writing: ', name)\n",
    "    except:\n",
    "           pass\n",
    "        \n",
    "        \n",
    "        '''\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
